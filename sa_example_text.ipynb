{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Sentences for TextBlob and Distilroberta models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook analyses two example sentences to compare the textblob and distilroberta models. The results are presented in the project report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polarity of text 1: 0.0, Subjectivity of text 1: 0.125\n",
      "Polarity of text 2: 0.8, Subjectivity of text 2: 0.75\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "# Sample sentences\n",
    "text_1 = \"The value of this stock will rise in the future!\"\n",
    "text_2 = \"This company is great.\"\n",
    "\n",
    "# Sentiment Analysis\n",
    "polarity_1 = TextBlob(text_1).sentiment.polarity\n",
    "subjectivity_1 = TextBlob(text_1).sentiment.subjectivity\n",
    "polarity_2 = TextBlob(text_2).sentiment.polarity\n",
    "subjectivity_2 = TextBlob(text_2).sentiment.subjectivity\n",
    "\n",
    "# Print the output\n",
    "print(f\"Polarity of text 1: {polarity_1}, Subjectivity of text 1: {subjectivity_1}\")\n",
    "print(f\"Polarity of text 2: {polarity_2}, Subjectivity of text 2: {subjectivity_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-28 22:27:39.669133: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Pro\n",
      "2024-07-28 22:27:39.669161: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2024-07-28 22:27:39.669168: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2024-07-28 22:27:39.669266: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-07-28 22:27:39.669321: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaForSequenceClassification: ['roberta.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label of text 1: positive, Score of text 1: 0.999525785446167\n",
      "Label of text 2: positive, Score of text 2: 0.8997927904129028\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Initialize the sentiment-analysis pipeline with the fine-tuned distilroberta model\n",
    "pipe = pipeline(\"text-classification\", model=\"mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis\")\n",
    "\n",
    "# Sentiment analysis\n",
    "result_1 = pipe(text_1)[0]\n",
    "label_1 = result_1['label']\n",
    "score_1 = result_1['score']\n",
    "\n",
    "result_2 = pipe(text_2)[0]\n",
    "label_2 = result_2['label']\n",
    "score_2 = result_2['score']\n",
    "\n",
    "# Print the output\n",
    "print(f\"Label of text 1: {label_1}, Score of text 1: {score_1}\")\n",
    "print(f\"Label of text 2: {label_2}, Score of text 2: {score_2}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
